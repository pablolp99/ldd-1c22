{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2543e02b-13c2-4cc5-ae00-dc00ca79190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfd4491d-0eb1-4b82-ab4f-b98a8f610e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_TT = {\n",
    "    \"Night\": 0,\n",
    "    \"Day\": 1,\n",
    "}\n",
    "\n",
    "def preprocess(df, weather_cols, wind_cols, pca_weather=None, pca_wind=None):\n",
    "    weather = df[weather_cols]\n",
    "    wind = df[wind_cols]\n",
    "    \n",
    "    # Begin preprocessing\n",
    "    df.columns = list(map(lambda c: c.lower(), df.columns))\n",
    "\n",
    "    # Fix datetimes\n",
    "    df.start_time = pd.to_datetime(df.start_time)\n",
    "    df.end_time = pd.to_datetime(df.end_time)\n",
    "    # df.weather_timestamp = pd.to_datetime(df.weather_timestamp)\n",
    "\n",
    "    df['start_day'] = df.start_time.apply(lambda x: x.day)\n",
    "    df['start_hour'] = df.start_time.apply(lambda x: x.hour)\n",
    "    df['end_day'] = df.end_time.apply(lambda x: x.day)\n",
    "    df['end_hour'] = df.end_time.apply(lambda x: x.hour)\n",
    "    df['time_diff'] = df.end_time - df.start_time\n",
    "    df['time_diff'] = df.time_diff.apply(lambda x: x.seconds)\n",
    "\n",
    "    df = df.drop(columns=['start_time', 'end_time', 'weather_timestamp'])\n",
    "\n",
    "    # Drop description\n",
    "    df = df.drop(columns=['description'])\n",
    "\n",
    "    # Drop other irrelevant information\n",
    "    df = df.drop(\n",
    "        columns=[\n",
    "            \"number\",\n",
    "            \"street\",\n",
    "            \"side\",\n",
    "            \"city\",\n",
    "            \"county\",\n",
    "            \"state\",\n",
    "            \"zipcode\",\n",
    "            \"country\",\n",
    "            \"timezone\",\n",
    "            \"airport_code\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Renaming cols\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"distance(mi)\": \"distance_mi\",\n",
    "            \"temperature(f)\": \"temperature_f\",\n",
    "            \"wind_chill(f)\": \"wind_chill_f\",\n",
    "            \"humidity(%)\": \"humidity_perc\",\n",
    "            \"pressure(in)\": \"pressure_in\",\n",
    "            \"visibility(mi)\": \"visibility_mi\",\n",
    "            \"wind_speed(mph)\": \"wind_speed_mph\",\n",
    "            \"precipitation(in)\": \"precipitation_in\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Convert to int bool columns\n",
    "    for c in [\"amenity\",\"bump\",\"crossing\",\"give_way\",\"junction\",\"no_exit\",\"railway\",\"roundabout\",\"station\",\"stop\",\"traffic_calming\",\"traffic_signal\",\"turning_loop\"]:\n",
    "        df[c] = df[c].astype(int)\n",
    "\n",
    "    # Vectorize weather\n",
    "    # weather = pd.get_dummies(df.weather_condition, prefix='weather')\n",
    "    # wind = pd.get_dummies(df.wind_direction, prefix='wind')\n",
    "\n",
    "    if pca_weather is None and pca_wind is None:\n",
    "        # Apply PCA to weather and wind\n",
    "        pca_weather = PCA(n_components=20)\n",
    "        weather_new = pca_weather.fit_transform(weather)\n",
    "        pca_wind = PCA(n_components=8)\n",
    "        wind_new = pca_wind.fit_transform(wind)\n",
    "    else:\n",
    "        weather_new = pca_weather.transform(weather)\n",
    "        wind_new = pca_wind.transform(wind)\n",
    "    \n",
    "    weather_new = pd.DataFrame(weather_new).rename(columns={ i:f\"weather_{i}\" for i in range(len(weather_new[0])) })\n",
    "    wind_new = pd.DataFrame(wind_new).rename(columns={ i:f\"wind_{i}\" for i in range(len(wind_new[0])) })\n",
    "\n",
    "    df = df.join(weather_new)\n",
    "    df = df.join(wind_new)\n",
    "\n",
    "    df = df.drop(\n",
    "        columns=[\n",
    "            \"weather_condition\",\n",
    "            \"wind_direction\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    df = df.drop(columns=list(map(lambda x: x.lower(), weather_cols+wind_cols)))\n",
    "\n",
    "    # Other columns\n",
    "    df.sunrise_sunset = df.sunrise_sunset.apply(lambda x: SS_TT[x])\n",
    "    df.civil_twilight = df.civil_twilight.apply(lambda x: SS_TT[x])\n",
    "    df.nautical_twilight = df.nautical_twilight.apply(lambda x: SS_TT[x])\n",
    "    df.astronomical_twilight = df.astronomical_twilight.apply(lambda x: SS_TT[x])\n",
    "    \n",
    "    return df, pca_weather, pca_wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646299e-4d9f-40ec-bc63-c4c032d78e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../train.csv\").drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a2ad4-ba4c-47b2-870c-83f8836b64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.get_dummies(df.Weather_Condition, prefix='weather')\n",
    "wind = pd.get_dummies(df.Wind_Direction, prefix='wind')\n",
    "\n",
    "df = df.join(weather)\n",
    "df = df.join(wind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3c644e2-69dd-4ad2-b901-86b7368bcb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, pca_w, pca_v = preprocess(df, list(weather.columns), list(wind.columns))\n",
    "# df_val, _, _ = preprocess(df_val, list(weather.columns), list(wind.columns), pca_weather=pca_w, pca_wind=pca_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba045e0b-7e85-4eb5-8f05-15ce454278df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a2a525b-d052-4d5e-9c96-81b9ed6995d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"train_.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a0b09-e3e9-4ce1-864c-ef91c758016a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07711a4f-c5aa-4e8d-9eee-be1e2f936f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = pd.read_csv(\"../test4alumnxs.csv\").drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5303e277-8086-4caf-8c83-1a2908fd9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_t = pd.get_dummies(df_t.Weather_Condition, prefix='weather')\n",
    "wind_t = pd.get_dummies(df_t.Wind_Direction, prefix='wind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "69f09287-93cf-4ca9-bdfe-8f570789a2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df_t.join(weather_t)\n",
    "df_t = df_t.join(wind_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "efd5aeab-9a65-4328-8f35-4ccaf5b7059b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weather_Blowing Dust',\n",
       " 'weather_Blowing Dust / Windy',\n",
       " 'weather_Blowing Snow',\n",
       " 'weather_Heavy Drizzle',\n",
       " 'weather_Heavy Snow / Windy',\n",
       " 'weather_Light Blowing Snow',\n",
       " 'weather_Light Freezing Fog',\n",
       " 'weather_Light Freezing Rain / Windy',\n",
       " 'weather_Light Rain Shower',\n",
       " 'weather_Light Snow Shower',\n",
       " 'weather_Sand / Dust Whirlwinds',\n",
       " 'weather_Snow / Windy',\n",
       " 'weather_Squalls / Windy',\n",
       " 'weather_T-Storm / Windy'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(set(df_t.columns).symmetric_difference(set(df.columns)) - {\"Severity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b9ef06b7-5094-4750-bc34-5fee56110115",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in set(df_t.columns).symmetric_difference(set(df.columns)) - {\"Severity\"}:\n",
    "    df_t[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a2eac46a-d142-4b04-97ba-369ea147d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_p, _, _ = preprocess(df_t, list(weather.columns), list(wind.columns), pca_weather=pca_w, pca_wind=pca_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cb71696b-a789-4a05-b531-31d6ac4ec050",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_p_p = df_t_p.drop(columns=['weather_blowing dust', 'weather_light snow shower', 'weather_t-storm / windy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8b601cd9-b848-4365-a810-3eda3f2caf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_p_p.to_csv(\"test4alumnos_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe21c07-d58c-4271-ac34-263ce192d68a",
   "metadata": {},
   "source": [
    "df_train.to_csv(\"train_rev.csv\", index=False)\n",
    "df_val.to_csv(\"val_rev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd69f73-43ee-496a-84fc-b18e7b941845",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f920d99-aec6-481d-a291-9154ff1ceb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../train.csv\").drop(columns=['Unnamed: 0.1', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7423fa05-11f5-4025-aed4-07596ae41f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.get_dummies(df.Weather_Condition, prefix='weather')\n",
    "wind = pd.get_dummies(df.Wind_Direction, prefix='wind')\n",
    "\n",
    "df = df.join(weather)\n",
    "df = df.join(wind)\n",
    "\n",
    "X = df.drop(columns=\"Severity\")\n",
    "y = df.Severity\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b39f101-77ab-4d31-b71d-898a4ea1eac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = X_train.join(y_train)\n",
    "df_test = X_test.join(y_test)\n",
    "\n",
    "df_train_t, pca_w_t, pca_v_t = preprocess(df_train, list(weather.columns), list(wind.columns))\n",
    "df_val_t, _, _ = preprocess(df_test, list(weather.columns), list(wind.columns), pca_weather=pca_w_t, pca_wind=pca_v_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "116bcc10-a701-4415-ab27-cd33e8a6bc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_t.to_csv(\"new_data/train_t.csv\")\n",
    "df_val_t.to_csv(\"new_data/train_val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa12234-72be-4a16-9334-401a6e24344d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.index.intersection(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f0a016-1b44-4f73-83d1-771d46c5f303",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "df['description_tokenized'] = df.description.apply(tokenize_sentence)\n",
    "\n",
    "X = df.drop(columns='severity')\n",
    "y = df.severity\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "df_train = X_train.join(y_train)\n",
    "df_test = X_test.join(y_test)\n",
    "\n",
    "tokenized_sent = df_train.description_tokenized\n",
    "\n",
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_sent)]\n",
    "\n",
    "model = Doc2Vec(tagged_data, vector_size = 20, window = 2, min_count = 1, epochs = 100)\n",
    "\n",
    "def try_vectorize(model, w):\n",
    "    try:\n",
    "        return vectorize(model, w)\n",
    "    except:\n",
    "        return model.infer_vector(doc_words=x, alpha=0.025)\n",
    "\n",
    "# model.infer_vector(doc_words=tokens_list, steps=20, alpha=0.025)\n",
    "df_train['description_vectorized'] = df_train.description_tokenized.apply(lambda x: vectorize(model, x))\n",
    "df_test['description_vectorized'] = df_test.description_tokenized.apply(lambda x: try_vectorize(model, x))\n",
    "\n",
    "_tt_df = df_train.description_vectorized.apply(pd.Series)\n",
    "_ts_df = df_test.description_vectorized.apply(pd.Series)\n",
    "\n",
    "_tt_df = _tt_df.rename(\n",
    "    columns={\n",
    "        i: f\"desc_{i}\" for i in range(20)\n",
    "    }\n",
    ")\n",
    "\n",
    "_ts_df = _ts_df.rename(\n",
    "    columns={\n",
    "        i: f\"desc_{i}\" for i in range(20)\n",
    "    }\n",
    ")\n",
    "\n",
    "df_train = df_train.drop(columns=['description_tokenized', 'description_vectorized', 'description'])\n",
    "df_test = df_test.drop(columns=['description_tokenized', 'description_vectorized', 'description'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
